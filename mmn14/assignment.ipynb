{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will encode the word 'cba' using arithmetic coding.\n",
    "\n",
    "\\begin{array}{|c|c|c|}\n",
    "  \\hline\n",
    "  \\textbf{Source Symbol} & \\textbf{Probability} & \\textbf{Subinterval} \\\\\n",
    "  \\hline\n",
    "  a & 0.5 & [0,0.5) \\\\\n",
    "  b & 0.2 & [0.5,0.7) \\\\\n",
    "  c & 0.15 & [0.7,0.85) \\\\\n",
    "  d & 0.1 & [0.85,0.95) \\\\\n",
    "  e & 0.05 & [0.95,1) \\\\\n",
    "  \\hline\n",
    "\\end{array}\n",
    "\n",
    "The first subinterval corresponds to 'c', and so it would be \\([0.7,0.85)\\).\\\n",
    "After renormalizing, the table will look like this:\n",
    "\n",
    "\\begin{array}{|c|c|c|}\n",
    "  \\hline\n",
    "  \\textbf{Source Symbol} & \\textbf{Probability} & \\textbf{Subinterval} \\\\\n",
    "  \\hline\n",
    "  a & 0.5 & [0.7,0.775) \\\\\n",
    "  b & 0.2 & [0.775,0.805) \\\\\n",
    "  c & 0.15 & [0.805,0.8275) \\\\\n",
    "  d & 0.1 & [0.8275,0.8425) \\\\\n",
    "  e & 0.05 & [0.8425,0.85) \\\\\n",
    "  \\hline\n",
    "\\end{array}\n",
    "\n",
    "The second subinterval would correspond to 'b' and so it would be\n",
    "$\\lbrack 0.775,0.805)$.\n",
    "\n",
    "Instead of calculating the final table, we'll just calculate the\n",
    "expected probability-\\\n",
    "The last character is 'a', meaning in the first half of the interval\n",
    "$\\lbrack 0.775,0.805)$.\\\n",
    "The interval is of size 0.03 and so half of it is of size 0.015.\\\n",
    "And so, the final subinterval for 'a' would be $\\lbrack 0.775,0.79)$.\n",
    "\n",
    "Finally, we will choose a number within that range(which represents\n",
    "cba), like [0.78]."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Projective transformations do not necessarily preserve parallelism.\n",
    "\n",
    "Projective transformations change the perspective of an\n",
    "object. So, for example, when viewing a rectangle from its side we can\n",
    "get the following change in perspective-\n",
    "\n",
    "![No Longer Parallel](imgs/parallelism.png)\n",
    "\n",
    "As we can see, the before-transformation parallel lines(top and bottom)\n",
    "are no longer parallel.\n",
    "\n",
    "We will now show an example.\n",
    "\n",
    "Let us choose the two parallel lines in Euclidian space $y = 2$ and\n",
    "$y = 1$, and consider the projective transformation $T$ represented by\n",
    "this matrix-\n",
    "\n",
    "$$A = \\begin{pmatrix}\n",
    "1 & 0 & 0 \\\\\n",
    "0 & 1 & 0 \\\\\n",
    "1 & 0 & 1\n",
    "\\end{pmatrix}$$\n",
    "\n",
    "Which transforms the coordinates of a point \\[$x,y,z\\rbrack$ like so-\n",
    "\n",
    "$$T\\left( \\lbrack x,y,z\\rbrack \\right) = \\lbrack x,y,z + x\\rbrack$$\n",
    "\n",
    "### The line y=1\n",
    "\n",
    "Let us pick two points on the line $y = 1$: $(0,1),(1,1)$\\\n",
    "The homogeneous coordinates of these points are $\\lbrack 0,1,1\\rbrack$\n",
    "and $\\lbrack 1,1,1\\rbrack$, respectively.\\\n",
    "Calculating their transformations results in-\n",
    "\n",
    "$T\\left( \\lbrack 0,1,1\\rbrack \\right) = \\lbrack 0,1,1\\rbrack$, which\n",
    "corresponds to $(0,1)$.\n",
    "\n",
    "$T\\left( \\lbrack 1,1,1\\rbrack \\right) = \\lbrack 1,1,2\\rbrack$, which\n",
    "corresponds to $\\left( \\frac{1}{2},\\frac{1}{2} \\right)$ (by dividing by\n",
    "the z component).\n",
    "\n",
    "These two points are represented by the line $y = - x + 1$\n",
    "\n",
    "### The line y=2\n",
    "\n",
    "Let us pick two points on the line $y = 2$: $(0,2)$, $(1,2)$\\\n",
    "Their corresponding homogenous coordinates are $\\lbrack 0,2,1\\rbrack$\n",
    "and $\\lbrack 1,2,1\\rbrack$.\n",
    "\n",
    "$T\\left( \\lbrack 0,2,1\\rbrack \\right) = \\lbrack 0,2,1\\rbrack$, which\n",
    "corresponds to $(0,2)$.\n",
    "\n",
    "$T\\left( \\lbrack 1,2,1\\rbrack \\right) = \\lbrack 1,2,2\\rbrack$, which\n",
    "corresponds to $\\left( \\frac{1}{2},1 \\right)$ (by dividing by the z\n",
    "component).\n",
    "\n",
    "These two points are represented by the line $y = - 2x + 2$\n",
    "\n",
    "Since the coefficients of $x$ aren't the same, the resulting two lines\n",
    "are not parallel- contradicting the initial statement.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The line is of size $2^{n}$, and so representing a position in that line requires $n$ bits.\n",
    "\n",
    "Furthermore, the length of each run also requires $n$ bits(since a run could take up to the entire line). And so, each run takes $2n$ bits.\n",
    "\n",
    "The start of the line is signaled by the pair $(0,0)$, which would also require $2n$ bits.\n",
    "\n",
    "We will mark the number of runs with $r$.\n",
    "\n",
    "And so we can conclude that $2n + r \\times 2n < 2^{n}$: The first $2n$\n",
    "coming from the start of the line, $r \\times 2n$ coming from the number\n",
    "of runs in the line, and $2^{n}$ being the upper bound of runs(as the\n",
    "image is of size $2^{n} \\times 2^{n}$).\n",
    "\n",
    "Simplifying, we get that\n",
    "\n",
    "\\begin{align*}\n",
    "    2n + r \\times 2n &< 2^{n} \\\\\n",
    "    2n(1 + r) &< 2^{n} \\\\\n",
    "    1 + r &< \\frac{2^{n}}{2n} = \\frac{2^{n - 1}}{n} \\\\\n",
    "    r &< \\frac{2^{n - 1}}{n} - 1\n",
    "\\end{align*}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plugging in $n = 10$ to our equation, we get that\n",
    "\n",
    "$$r < \\frac{2^{9}}{10} - 1 = \\frac{512}{10} - 1 = 50.2$$\n",
    "\n",
    "And so the maxumim value is 50.2, or 50 when rounded down."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ideal bit-per-pixel ratio would be 5.3 bits/pixel.\n",
    "\n",
    "Assuming the original image uses 8-bit pixels(grayscale), we get that the maximum compression would be\n",
    "\n",
    "$$\\frac{5.3\\frac{bits}{pixel}}{8\\frac{bits}{pixel}} = 0.6625$$\n",
    "\n",
    "Meaning that the image may be compressed to about $66.3\\%$ of its\n",
    "original size.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Huffman coding is optimal for memoryless sources, reaching the entropy limit when the symbol probabilities are powers of $\\frac{1}{2}$.\n",
    "\n",
    "Since many(if not most) pixel probabilities are not powers of $\\frac{1}{2}$, the resulting average $\\frac{bit}{pixel}$ would be more than the entropy.\n",
    "\n",
    "We could also consider the fact that if the probability tree isn't\n",
    "shared beforehand, we would also need to transmit the tree itself-\n",
    "adding additional overhead to the encoding.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could preprocess the image to remove redundancies- either reducing spatial redundancy or removing information that is irrelevant to the image.\n",
    "\n",
    "If we would like to not do any preprocessing on the image, we could change the encoding method altogether, to a coding method that is more efficient, such as arithmetic encoding."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use equation 8-6:\n",
    "\n",
    "$$H = - \\sum_{j = 1}^{J}{P\\left( a_{j} \\right)\\log{P\\left( a_{j} \\right)}}$$\n",
    "\n",
    "$$a = \\left\\{ a_{1} = 21,a_{2} = 95,a_{3} = 169,a_{4} = 243 \\right\\}$$\n",
    "\n",
    "$${P\\left( a_{1} \\right) = P(21) = \\frac{12}{32} = \\frac{3}{8}}$$\n",
    "$${P\\left( a_{2} \\right) = P(95) = \\frac{4}{32} = \\frac{1}{8}}$$\n",
    "$${P\\left( a_{3} \\right) = P(169) = \\frac{4}{32} = \\frac{1}{8}}$$\n",
    "$${P\\left( a_{4} \\right) = P(243) = \\frac{12}{32} = \\frac{3}{8}}$$\n",
    "\n",
    "Plugging these values into equation 8-6, we get that\n",
    "\n",
    "\\begin{align*}\n",
    "    H &= - \\sum_{j = 1}^{J} P\\left( a_{j} \\right)\\log{P\\left( a_{j} \\right)} \\\\\n",
    "      &= - \\sum_{j = 1}^{4} P\\left( a_{j} \\right)\\log{P\\left( a_{j} \\right)} \\\\\n",
    "      &= - 1 \\times \\left( \\frac{3}{8}\\log\\left( \\frac{3}{8} \\right) + \\frac{1}{8}\\log\\left( \\frac{1}{8} \\right) + \\frac{1}{8}\\log\\left( \\frac{1}{8} \\right) + \\frac{3}{8}\\log\\left( \\frac{3}{8} \\right) \\right) \\\\\n",
    "      &= - 2 \\times \\left( \\frac{3}{8}\\log\\left( \\frac{3}{8} \\right) + \\frac{1}{8}\\log\\left( \\frac{1}{8} \\right) \\right) \\\\\n",
    "      &= - \\frac{2}{8} \\times \\left( 3\\log(3) - 3\\log(8) - \\log(8) \\right) \\\\\n",
    "      &= - \\frac{1}{4} \\times \\left( 3\\log(3) - 12\\log(2) \\right) \\\\\n",
    "      &= \\frac{3}{4}\\left( 4 - \\log(3) \\right) \\\\\n",
    "      &\\approx 1.811 \\frac{\\text{bit}}{\\text{symbol}} = 1.811 \\frac{\\text{bit}}{\\text{pixel}}\n",
    "\\end{align*}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Huffman Coding](imgs/huffman-coding.png)\n",
    "\n",
    "\n",
    "Applying the encoding on our original image, we get that\n",
    "\n",
    "$${Im = \\begin{pmatrix}\n",
    "21 & 21 & 21 & 95 & 169 & 243 & 243 & 243 \\\\\n",
    "21 & 21 & 21 & 95 & 169 & 243 & 243 & 243 \\\\\n",
    "21 & 21 & 21 & 95 & 169 & 243 & 243 & 243 \\\\\n",
    "21 & 21 & 21 & 95 & 169 & 243 & 243 & 243\n",
    "\\end{pmatrix}\n",
    "}{\\Longrightarrow \\begin{pmatrix}\n",
    "1 & 1 & 1 & 010 & 011 & 00 & 00 & 00 \\\\\n",
    "1 & 1 & 1 & 010 & 011 & 00 & 00 & 00 \\\\\n",
    "1 & 1 & 1 & 010 & 011 & 00 & 00 & 00 \\\\\n",
    "1 & 1 & 1 & 010 & 011 & 00 & 00 & 00\n",
    "\\end{pmatrix}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Average compression-\n",
    "\n",
    "$$L_{avg} = \\frac{3}{8} \\times 1 + \\frac{3}{8} \\times 2 + \\frac{1}{8} \\times 3 + \\frac{1}{8} \\times 3 = \\frac{15}{8}\\frac{bit}{pixel} = 1.875\\frac{bit}{pixel}$$\n",
    "\n",
    "Compression ratio-\n",
    "\n",
    "$$C_{Huffman} = \\frac{b}{b^{'}} = \\frac{b}{L_{avg}} = \\frac{N \\times 8}{N \\times \\left( \\frac{15}{8} \\right)} = \\frac{64}{15} \\approx 4.27$$\n",
    "\n",
    "And so, the compression is $4.27:1$.\n",
    "\n",
    "The minimal compression is $C_{\\min} = \\frac{b}{H}$\n",
    "\n",
    "And so, the effectiveness of huffman compression is\n",
    "\n",
    "$$\\frac{C_{Huffman}}{C_{\\min}} = \\frac{\\left( \\frac{b}{b^{'}} \\right)}{\\left( \\frac{b}{H} \\right)} = \\frac{H}{b^{'}} = \\frac{H}{L_{avg}} = \\frac{1.811}{1.875} \\approx 0.966$$\n",
    "\n",
    "Meaning that Huffman encoding achieves 96.6% effectiveness compared to\n",
    "the optimal compression.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The existing pairs in each line are- $(21,21)$, $(21,95)$, $(95,169)$,\n",
    "$(169,\\ 243)$ and $(243,243)$.\\\n",
    "Since the image is stored continuously, there are also the pairs between\n",
    "the last element of a line and the first element of the next line. And\n",
    "so, there's also the pair $(243,21)$.\n",
    "\n",
    "So there are 6 possible pairs-\n",
    "\n",
    "$$a = \\left\\{ \\begin{array}{r}\n",
    "a_{1} = (21,21),\\ a_{2} = (21,95),a_{3} = (95,169), \\\\\n",
    "a_{4} = (169,\\ 243),a_{5} = (243,243),a_{6} = (243,21)\n",
    "\\end{array} \\right\\}$$\n",
    "\n",
    "And there are a total of 32 pairs in the image.\n",
    "\n",
    "\\begin{align*}\n",
    "    P\\left( a_{1} \\right) &= P\\left( (21,21) \\right) = \\frac{8}{32} = \\frac{1}{4} \\\\\n",
    "    P\\left( a_{2} \\right) &= P\\left( (21,95) \\right) = \\frac{4}{32} = \\frac{1}{8} \\\\\n",
    "    P\\left( a_{3} \\right) &= P\\left( (95,169) \\right) = \\frac{4}{32} = \\frac{1}{8} \\\\\n",
    "    P\\left( a_{4} \\right) &= P\\left( (169,243) \\right) = \\frac{4}{32} = \\frac{1}{8} \\\\\n",
    "    P\\left( a_{5} \\right) &= P\\left( (243,243) \\right) = \\frac{8}{32} = \\frac{1}{4} \\\\\n",
    "    P\\left( a_{6} \\right) &= P\\left( (243,21) \\right) = \\frac{4}{32} = \\frac{1}{8}\n",
    "\\end{align*}\n",
    "\n",
    "Plugging these values into the entropy equation we get that-\n",
    "\n",
    "\\begin{align*}\n",
    "    H &= - \\sum_{j = 1}^{J} P\\left( a_{j} \\right)\\log{P\\left( a_{j} \\right)} \\\\\n",
    "      &= - \\sum_{j = 1}^{6} P\\left( a_{j} \\right)\\log{P\\left( a_{j} \\right)} \\\\\n",
    "      &= - \\left( 2 \\times \\frac{1}{4}\\log\\left( \\frac{1}{4} \\right) + 4 \\times \\frac{1}{8}\\log\\left( \\frac{1}{8} \\right) \\right) \\\\\n",
    "      &= - \\frac{1}{2}\\left( - \\log(4) - \\log(8) \\right) \\\\\n",
    "      &= \\frac{1}{2}(2 + 3) = \\frac{5}{2} \\\\\n",
    "      &= 2.5 \\frac{\\text{bit}}{\\text{symbol}} \\\\\n",
    "      &= 2.5 \\frac{\\text{bit}}{2 \\times \\text{pixel}} \\\\\n",
    "      &= 1.25 \\frac{\\text{bit}}{\\text{pixel}}\n",
    "\\end{align*}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assuming we take the difference in every row separately\n",
    "\n",
    "$$\\begin{pmatrix}\n",
    "21 & 0 & 0 & 74 & 74 & 74 & 0 & 0 \\\\\n",
    "21 & 0 & 0 & 74 & 74 & 74 & 0 & 0 \\\\\n",
    "21 & 0 & 0 & 74 & 74 & 74 & 0 & 0 \\\\\n",
    "21 & 0 & 0 & 74 & 74 & 74 & 0 & 0\n",
    "\\end{pmatrix}$$\n",
    "\n",
    "We shall calculate the entropy-\n",
    "\n",
    "$$a = \\left\\{ a_{1} = 21,a_{2} = 0,a_{3} = 74 \\right\\}$$\n",
    "\n",
    "$${P\\left( a_{1} \\right) = P(21) = \\frac{4}{32} = \\frac{1}{8}\n",
    "}{P\\left( a_{2} \\right) = P(0) = \\frac{16}{32} = \\frac{1}{2}\n",
    "}{P\\left( a_{3} \\right) = P(74) = \\frac{12}{32} = \\frac{3}{8}}$$\n",
    "\n",
    "And so,\n",
    "\n",
    "\\begin{align*}\n",
    "    H &= - \\sum_{j = 1}^{J} P\\left( a_{j} \\right)\\log{P\\left( a_{j} \\right)} \\\\\n",
    "      &= - \\sum_{j = 1}^{3} P\\left( a_{j} \\right)\\log{P\\left( a_{j} \\right)} \\\\\n",
    "      &= - \\left( \\frac{1}{8}\\log\\left( \\frac{1}{8} \\right) + \\frac{1}{2}\\log\\left( \\frac{1}{2} \\right) + \\frac{3}{8}\\log\\left( \\frac{3}{8} \\right) \\right) \\\\\n",
    "      &= - \\frac{1}{8}\\left( - 3 - 4 + 3\\left( \\log 3 - 3 \\right) \\right) \\\\\n",
    "      &= 2 - \\frac{3}{8}\\log 3 \\\\\n",
    "      &\\approx 1.406 \\frac{\\text{bit}}{\\text{symbol}} = 1.406 \\frac{\\text{bit}}{\\text{pixel}}\n",
    "\\end{align*}\n",
    "The entropy is lower than the original encoding, telling us that\n",
    "there's a correlation between pixels and that this is a better\n",
    "compression method compared to compressing the original image directly.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, the image has correlation between pairs of pixels(at the very least).\n",
    "\n",
    "In (a), the correlation between pixels is not taken into account.\n",
    "\n",
    "In (d) we do take that correlation into account, resulting in lower entropy- indicating the existance of spatial redundancy in the initial image.\n",
    "\n",
    "In (e) we also take that correlation into account, but not as much as (d)- likely because it didn't remove all of the correlation.\n",
    "\n",
    "$$H_{(d)} < H_{(e)} < H_{(a)}$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.14"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will follow the process in the book. $k = 2$.\n",
    "\n",
    "$$\\sum_{j = 0}^{i - 1}2^{j + 2} \\leq n < \\sum_{j = 0}^{i}2^{j + 2}\n",
    "$$\n",
    "$i = 0$ works for $0 \\leq n \\leq 3$\n",
    "\n",
    "The unary code is $0$.\n",
    "\n",
    "$$n - \\sum_{j = 0}^{- 1}2^{j + 2} = n$$\n",
    "\n",
    "We want $k + i = 2$ bits, and so we get $00,01,10,11$.\n",
    "\n",
    "We will now concatenate the results-\n",
    "\n",
    "\\begin{align*}\n",
    "    G_{\\exp}^{2}(0) &= 000 \\\\\n",
    "    G_{\\exp}^{2}(1) &= 001 \\\\\n",
    "    G_{\\exp}^{2}(2) &= 010 \\\\\n",
    "    G_{\\exp}^{2}(3) &= 011\n",
    "\\end{align*}\n",
    "\n",
    "$i = 1$ works for $4 \\leq n \\leq 11$.\n",
    "\n",
    "The unary code is $10$.\n",
    "\n",
    "$$n - \\sum_{j = 0}^{0}2^{j + 2} = n - 4$$\n",
    "\n",
    "We want $k + i = 3$ bits, and so we get\n",
    "$000,001,010,011,100,101,110,111$\n",
    "\n",
    "We will now concatenate the results-\n",
    "\n",
    "\\begin{align*}\n",
    "    G_{\\exp}^{2}(4) &= 10000 \\\\\n",
    "    G_{\\exp}^{2}(5) &= 10001 \\\\\n",
    "    G_{\\exp}^{2}(6) &= 10010 \\\\\n",
    "    G_{\\exp}^{2}(7) &= 10011 \\\\\n",
    "    G_{\\exp}^{2}(8) &= 10100 \\\\\n",
    "    G_{\\exp}^{2}(9) &= 10101 \\\\\n",
    "    G_{\\exp}^{2}(10) &= 10110 \\\\\n",
    "    G_{\\exp}^{2}(11) &= 10111\n",
    "\\end{align*}\n",
    "\n",
    "$i = 2$ works for $12 \\leq n \\leq 27$ and specifically for\n",
    "$12 \\leq n \\leq 15$.\n",
    "\n",
    "The unary code is $110$.\n",
    "\n",
    "$$n - \\sum_{j = 0}^{1}2^{j + 2} = n - 4 - 8 = n - 12$$\n",
    "\n",
    "We want $k + i = 4$ bits, and so we get $0000,0001,0010,0011$\n",
    "\n",
    "We will now concatenate the results-\n",
    "\n",
    "\\begin{align*}\n",
    "    G_{\\exp}^{2}(12) &= 1100000 \\\\\n",
    "    G_{\\exp}^{2}(13) &= 1100001 \\\\\n",
    "    G_{\\exp}^{2}(14) &= 1100010 \\\\\n",
    "    G_{\\exp}^{2}(15) &= 1100011\n",
    "\\end{align*}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unlike DFT, the DCT produces only real coefficients, while the DFT produces complex coefficients.\n",
    "Working with complex numbers makes both the computation and the quantization process more complex- making DCT more efficient for image compression.\n",
    "\n",
    "Additionally, the DCT is even and symmetric along the y-axis, minimizing discontinuities compared to the DFT, which does not.\n",
    "The reduced discontinuities result in more of the information(energy) being stored in the low-frequency coefficients- meaning the higher-frequency coefficients have less impact.\n",
    "And so, we could remove those higher-frequency components without losing much of the information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The amount of intensity levels remains the same, and the probability of each intensity level remains the same(after mapping).\n",
    "\n",
    "The intensity level itself does not matter, only its probability and the amount of intensity levels.\n",
    "Therefore, the histogram equalization would have no effect on the following Huffman encoding."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LZW's advantage lies in reducing spatial redundancy, while Huffman encoding relies on encoding each symbol by itself, based on probability.\n",
    "\n",
    "Huffman requires two passages on the data- one for the probability tree and one for the actual data, while LZW requires only a single passage on the data.\n",
    "\n",
    "Moreover, LZW doesn't need any previous data about the probabilities of symbols before encoding.\n",
    "\n",
    "Additionally, Huffman requires transmitting the tree as well(if it\n",
    "wasn't agreed upon by the two parties), unlike LZW."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Golomb's advantage becomes apparent when smaller values occur very often, with the probabilities decreasing exponentially as values increase.\n",
    "\n",
    "In Golomb coding, smaller values are assigned shorter codes.\n",
    "Therefore, when the data follows a geometric distribution(meaning smaller values are much more frequent than larger values, and the probability decreases exponentially as the value increases) Golomb coding would be better than Huffman coding.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
